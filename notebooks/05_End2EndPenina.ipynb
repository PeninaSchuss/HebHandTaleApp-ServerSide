{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "095150d7-4f39-408b-ad2b-20f9c0a0477b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\User\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\python.exe'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f790b8b9-25bc-4dd9-8e6f-0805f0a11e2b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549bd307-8d5c-4268-9996-59bf9d0d02e3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd180b5d-e976-41fa-b381-1c5c9be47e29",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 2 - Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a5ed0fed-c62d-4eab-9f96-032d4979f7dd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import load_img\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from keras.models import Sequential\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.layers import Dense, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "357d5061-91a1-4995-9c91-884e5514084e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "INPUT_IMAGE_SIZE = (32, 32, 3)\n",
    "\n",
    "\n",
    "# prepare a list of image files to be loaded\n",
    "def image_files(input_directory):\n",
    "    filepaths = []\n",
    "    labels = []\n",
    "\n",
    "    digit_folders = os.listdir(input_directory)\n",
    "    # print(digit_folders)\n",
    "\n",
    "    for digit in digit_folders:\n",
    "        path = os.path.join(input_directory, digit)\n",
    "        flist = os.listdir(path)\n",
    "        for f in flist:\n",
    "            fpath = os.path.join(path, f)\n",
    "            filepaths.append(fpath)\n",
    "            labels.append(digit)\n",
    "    return filepaths, labels\n",
    "\n",
    "\n",
    "def load_images(filepaths):\n",
    "    images = []\n",
    "    for i in tqdm(range(len(filepaths))):\n",
    "        img = load_img(filepaths[i], target_size=INPUT_IMAGE_SIZE, grayscale=False)\n",
    "        img = img_to_array(img)\n",
    "        img.astype('float32')\n",
    "        img = img / 255\n",
    "        images.append(img)\n",
    "\n",
    "    images = np.array(images)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "0c52181a-9260-4085-8f0b-9798a1a69402",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR_TRAIN = 'TRAIN'\n",
    "SEED           = 42\n",
    "EPOCHS         = 7\n",
    "\n",
    "\n",
    "def load_vgg_model():\n",
    "    vgg19 = VGG19(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=INPUT_IMAGE_SIZE\n",
    "    )\n",
    "    model = Sequential()\n",
    "    model.add(vgg19)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(28, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='sgd',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_model(model):\n",
    "    # load the paths and labels in differnt variables\n",
    "    filepaths, labels = image_files(DATA_DIR_TRAIN) # 5,099 files\n",
    "    print(f'Using {len(filepaths):,} files for training.')\n",
    "    # load the 10K images\n",
    "    images = load_images(filepaths)\n",
    "    y = to_categorical(labels, num_classes=28)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(images, y, random_state=SEED, test_size=0.2)\n",
    "    print('X_train.shape:', X_train.shape)\n",
    "    print('X_test.shape:',  X_test.shape)\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=128,\n",
    "        validation_data=(X_test, y_test)\n",
    "    )\n",
    "    score = model.evaluate(X_test, y_test)\n",
    "    print('score: ',score)\n",
    "    # evaluate the model on your test data\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "    print('Test loss: ', test_loss)\n",
    "    print('Test accuracy: ', test_accuracy)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "a6e2b446-8cf1-458d-bcf5-8be31119d0ab",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg19 (Functional)          (None, 1, 1, 512)         20024384  \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 28)                14364     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,038,748\n",
      "Trainable params: 20,038,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = load_vgg_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d452cf11-d4e1-4102-8747-c2796f0ad96f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Model Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "a92d4b81-3190-44c1-b2f8-928a61b9d089",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4,944 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 4944/4944 [00:07<00:00, 673.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (3955, 32, 32, 3)\n",
      "X_test.shape: (989, 32, 32, 3)\n",
      "Epoch 1/7\n",
      "31/31 [==============================] - 202s 6s/step - loss: 2.6808 - accuracy: 0.2523 - val_loss: 2.3918 - val_accuracy: 0.4489\n",
      "Epoch 2/7\n",
      "31/31 [==============================] - 212s 7s/step - loss: 1.3587 - accuracy: 0.6066 - val_loss: 0.7982 - val_accuracy: 0.7604\n",
      "Epoch 3/7\n",
      "31/31 [==============================] - 219s 7s/step - loss: 0.6692 - accuracy: 0.7879 - val_loss: 0.6035 - val_accuracy: 0.7917\n",
      "Epoch 4/7\n",
      "31/31 [==============================] - 216s 7s/step - loss: 0.4674 - accuracy: 0.8417 - val_loss: 0.4724 - val_accuracy: 0.8686\n",
      "Epoch 5/7\n",
      "31/31 [==============================] - 227s 7s/step - loss: 0.3837 - accuracy: 0.8761 - val_loss: 0.5359 - val_accuracy: 0.8301\n",
      "Epoch 6/7\n",
      "31/31 [==============================] - 215s 7s/step - loss: 0.3320 - accuracy: 0.8918 - val_loss: 0.4955 - val_accuracy: 0.8423\n",
      "Epoch 7/7\n",
      "31/31 [==============================] - 231s 7s/step - loss: 0.2883 - accuracy: 0.9014 - val_loss: 0.4337 - val_accuracy: 0.8605\n",
      "31/31 [==============================] - 6s 202ms/step - loss: 0.4337 - accuracy: 0.8605\n",
      "score:  [0.43373796343803406, 0.8604651093482971]\n",
      "31/31 [==============================] - 7s 231ms/step - loss: 0.4337 - accuracy: 0.8605\n",
      "Test loss:  0.43373796343803406\n",
      "Test accuracy:  0.8604651093482971\n"
     ]
    }
   ],
   "source": [
    "history = train_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "b57d0802-cd4f-4f12-99aa-b30dc0fb85a8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5a3d10e2-c420-4123-9b3e-26d08ea3f4c8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define a dictionary to map the classification index to Hebrew letters\n",
    "abc = \"אבגדהוזחטיכךלמםנןסעפףצץקרשת,\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee5407d-4daa-4262-b499-19f153ff2935",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 3 - Word Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "822a9953-5830-4fe6-84b3-2a310d11be19",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "\n",
    "MIN_EDIT_DISTANCE_LENGTH = 1\n",
    "\n",
    "def get_word_suggestions(word):\n",
    "    closest_words = []\n",
    "    for vocab_word in tqdm(words):\n",
    "        lev_dist_word = lev_dist(word, vocab_word)\n",
    "        if lev_dist_word <= MIN_EDIT_DISTANCE_LENGTH:\n",
    "            closest_words.append(vocab_word)\n",
    "    return closest_words\n",
    "\n",
    "def lev_dist(a, b):\n",
    "    '''\n",
    "    This function will calculate the levenshtein distance between two input\n",
    "    strings a and b\n",
    "    example: a = 'stamp', b = 'stomp', lev_dist(a,b) >> 1.0\n",
    "    '''\n",
    "    @lru_cache(None)  # for memorization\n",
    "    def min_dist(s1, s2):\n",
    "\n",
    "        if s1 == len(a) or s2 == len(b):\n",
    "            return len(a) - s1 + len(b) - s2\n",
    "\n",
    "        # no change required\n",
    "        if a[s1] == b[s2]:\n",
    "            return min_dist(s1 + 1, s2 + 1)\n",
    "\n",
    "        return 1 + min(\n",
    "            min_dist(s1, s2 + 1),      # insert character\n",
    "            min_dist(s1 + 1, s2),      # delete character\n",
    "            min_dist(s1 + 1, s2 + 1),  # replace character\n",
    "        )\n",
    "\n",
    "    return min_dist(0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6de94d2-8798-4b39-b388-0aa6c391abc1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# End2End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ddb21ce3-bacd-4225-bc8d-0b9feffd6eed",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\User\\\\Desktop\\\\כללי\\\\שנה ג\\\\פרויקט גמר\\\\HandwritingProject\\\\michtav.png'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = 'michtav.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a5e79d4b-c19e-4146-97ac-28ae897dc379",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def image_to_text(image_path):\n",
    "    # Step 1 - Segmentation\n",
    "    assert os.path.exists(image_path)\n",
    "    characters = process_image(image_path)\n",
    "    # Step 2 - Classification\n",
    "    return characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "33cb4871",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "68425759",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "michtav.png\n",
      "(97, 293, 3)\n",
      "uint8\n",
      "Component=0, Original char size: (97, 293, 3), New char size: (56, 50, 3)\n",
      "Original char size: (97, 293, 3), New char size: (56, 50, 3)\n",
      "Component=1, Original char size: (97, 293, 3), New char size: (70, 69, 3)\n",
      "Original char size: (97, 293, 3), New char size: (70, 69, 3)\n",
      "Component=2, Original char size: (97, 293, 3), New char size: (50, 88, 3)\n",
      "Original char size: (97, 293, 3), New char size: (50, 88, 3)\n",
      "Component=3, Original char size: (97, 293, 3), New char size: (51, 61, 3)\n",
      "Original char size: (97, 293, 3), New char size: (51, 61, 3)\n"
     ]
    }
   ],
   "source": [
    "print(image_path)\n",
    "img = cv2.imread(image_path)\n",
    "print(img.shape)  # prints the shape of the image (rows, columns, channels)\n",
    "print(img.dtype)  # prints the data type of the image (e.g. uint8)\n",
    "# 01 - Load the image\n",
    "\n",
    "# 02 - Convert the image to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # numpy.ndarray, (257, 522)\n",
    "# 03 - Apply thresholding to convert the image to binary\n",
    "_, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "# 04 - Perform connected component analysis to separate the characters\n",
    "connected_components_output = cv2.connectedComponentsWithStats(thresh, connectivity=8)\n",
    "# 05 - Extract characters\n",
    "# chars = _process_characters(connected_components_output)\n",
    "num_labels, labels, stats, centroids = connected_components_output\n",
    "# Get the number of characters (excluding the background)\n",
    "num_chars = num_labels - 1\n",
    "# Define a list to store individual characters\n",
    "chars = []\n",
    "chars_cropped = []\n",
    "# Define a list to store the coordinates of each character\n",
    "coords = []\n",
    "# Loop through each character\n",
    "for i in range(num_chars):\n",
    "    # Add char\n",
    "    char = labels == i + 1\n",
    "    char = np.stack([char]*3, axis=-1).astype(np.uint8) * 255\n",
    "    char = cv2.bitwise_not(char)\n",
    "    chars.append(char)\n",
    "    # NEW - Add cropped char\n",
    "    x, y, w, h, area = stats[i + 1]\n",
    "    print(f'Component={i}, Original char size: {char.shape}, New char size: {char[y:y+h, x:x+w].shape}')\n",
    "#     char = labels == i + 1\n",
    "    char_cropped = char[y:y+h, x:x+w]\n",
    "    if char_cropped.shape[0] != char_cropped.shape[1]:\n",
    "            max_dim = max(char_cropped.shape[0], char_cropped.shape[1])\n",
    "            # Calculate the amount of padding required\n",
    "            top = (max_dim - char_cropped.shape[0]) // 2\n",
    "            bottom = max_dim - char_cropped.shape[0] - top\n",
    "            left = (max_dim - char_cropped.shape[1]) // 2\n",
    "            right = max_dim - char_cropped.shape[1] - left\n",
    "            # Add padding to the image\n",
    "            char_cropped = cv2.copyMakeBorder(char_cropped, top, bottom, left, right, cv2.BORDER_CONSTANT, value=[255, 255, 255])\n",
    "    chars_cropped.append(char_cropped)\n",
    "    \n",
    "    print(f'Original char size: {char.shape}, New char size: {char[y:y+h, x:x+w].shape}')\n",
    "\n",
    "    coords.append(stats[i+1][:2])\n",
    "    # print(coords)\n",
    "# Sort the characters based on their x-coordinates (from right to left)\n",
    "chars_cropped = [char for _, char in sorted(zip(coords, chars_cropped), key=lambda x: x[0][0], reverse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "abbbdeed-617e-42bb-8fbf-c7a8d00bb3be",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(chars_cropped[2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "2194fd26-e6b8-42dc-9ad1-c1bcfc994063",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61,)\n",
      "(61,)\n",
      "(61,)\n",
      "(61,)\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_chars):\n",
    "    print(char_cropped[i].shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "0e3e96ed-4b78-4f6a-bda8-cf67fc5916cc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 469509/469509 [00:19<00:00, 23766.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested words:\n",
      "1. אכתב\n",
      "2. הכתב\n",
      "3. יכתב\n",
      "4. כתב\n",
      "5. מוכתב\n",
      "6. מכותב\n",
      "7. מכזב\n",
      "8. מככב\n",
      "9. מכת\n",
      "10. מכתב\n",
      "11. מכתבה\n",
      "12. מכתבו\n",
      "13. מכתבי\n",
      "14. מכתבך\n",
      "15. מכתבם\n",
      "16. מכתבן\n",
      "17. מכתבת\n",
      "18. מכתיב\n",
      "19. מכתם\n",
      "20. מכתר\n",
      "21. מכתש\n",
      "22. מכתת\n",
      "23. מנתב\n",
      "24. משכתב\n",
      "25. מתכתב\n",
      "26. נכתב\n",
      "27. שכתב\n",
      "28. תכתב\n",
      "29. מכתה\n",
      "30. מכתו\n",
      "31. מכתך\n",
      "32. מכתן\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Choose a word from the list (enter the number):  10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You chose: מכתב\n"
     ]
    }
   ],
   "source": [
    "suggested_words = get_word_suggestions(predicted_letters_str)\n",
    "\n",
    "if len(suggested_words) == 0:\n",
    "    print(\"No matching words found.\")\n",
    "else:\n",
    "    print(\"Suggested words:\")\n",
    "    for i, word in enumerate(suggested_words):\n",
    "        print(f\"{i + 1}. {word}\")\n",
    "    choice = input(\"Choose a word from the list (enter the number): \")\n",
    "    chosen_word = suggested_words[int(choice) - 1]\n",
    "    print(f\"You chose: {chosen_word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ab14a9-8dd3-4c05-903e-236712449922",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}